{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "# if IN_COLAB:\n",
    "#     !apt install python-opengl\n",
    "#     !apt install ffmpeg\n",
    "#     !apt install xvfb\n",
    "#     !pip install PyVirtualDisplay==3.0\n",
    "#     !pip install gym==0.21.0\n",
    "#     from pyvirtualdisplay import Display\n",
    "    \n",
    "#     # Start virtual display\n",
    "#     dis = Display(visible=0, size=(400, 400))\n",
    "#     dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ReplayBuffer:\n",
    "#     \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         obs_dim: int, \n",
    "#         size: int, \n",
    "#         batch_size: int = 32, \n",
    "#         n_step: int = 1, \n",
    "#         gamma: float = 0.99\n",
    "#     ):\n",
    "#         self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "#         self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "#         self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "#         self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "#         self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "#         self.max_size, self.batch_size = size, batch_size\n",
    "#         self.ptr, self.size, = 0, 0\n",
    "        \n",
    "#         # for N-step Learning\n",
    "#         self.n_step_buffer = deque(maxlen=n_step)\n",
    "#         self.n_step = n_step\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def store(\n",
    "#         self, \n",
    "#         obs: np.ndarray, \n",
    "#         act: np.ndarray, \n",
    "#         rew: float, \n",
    "#         next_obs: np.ndarray, \n",
    "#         done: bool,\n",
    "#     ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "#         transition = (obs, act, rew, next_obs, done)\n",
    "#         self.n_step_buffer.append(transition)\n",
    "\n",
    "#         # single step transition is not ready\n",
    "#         if len(self.n_step_buffer) < self.n_step:\n",
    "#             return ()\n",
    "        \n",
    "#         # make a n-step transition\n",
    "#         rew, next_obs, done = self._get_n_step_info(\n",
    "#             self.n_step_buffer, self.gamma\n",
    "#         )\n",
    "#         obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "#         self.obs_buf[self.ptr] = obs\n",
    "#         self.next_obs_buf[self.ptr] = next_obs\n",
    "#         self.acts_buf[self.ptr] = act\n",
    "#         self.rews_buf[self.ptr] = rew\n",
    "#         self.done_buf[self.ptr] = done\n",
    "#         self.ptr = (self.ptr + 1) % self.max_size\n",
    "#         self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "#         return self.n_step_buffer[0]\n",
    "\n",
    "#     def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "#         idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "#         return dict(\n",
    "#             obs=self.obs_buf[idxs],\n",
    "#             next_obs=self.next_obs_buf[idxs],\n",
    "#             acts=self.acts_buf[idxs],\n",
    "#             rews=self.rews_buf[idxs],\n",
    "#             done=self.done_buf[idxs],\n",
    "#             # for N-step Learning\n",
    "#             indices=idxs,\n",
    "#         )\n",
    "    \n",
    "#     def sample_batch_from_idxs(\n",
    "#         self, idxs: np.ndarray\n",
    "#     ) -> Dict[str, np.ndarray]:\n",
    "#         # for N-step Learning\n",
    "#         return dict(\n",
    "#             obs=self.obs_buf[idxs],\n",
    "#             next_obs=self.next_obs_buf[idxs],\n",
    "#             acts=self.acts_buf[idxs],\n",
    "#             rews=self.rews_buf[idxs],\n",
    "#             done=self.done_buf[idxs],\n",
    "#         )\n",
    "    \n",
    "#     def _get_n_step_info(\n",
    "#         self, n_step_buffer: Deque, gamma: float\n",
    "#     ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "#         \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "#         # info of the last transition\n",
    "#         rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "#         for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "#             r, n_o, d = transition[-3:]\n",
    "\n",
    "#             rew = r + gamma * rew * (1 - d)\n",
    "#             next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "#         return rew, next_obs, done\n",
    "\n",
    "#     def __len__(self) -> int:\n",
    "#         return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        c,h,w = obs_dim\n",
    "        self.obs_buf = np.zeros([size, c,h,w ], dtype=np.uint8)\n",
    "        self.next_obs_buf = np.zeros([size, c,h,w ], dtype=np.uint8)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=idxs,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.randn(size)\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(nn.Module):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         in_dim: int, \n",
    "#         out_dim: int, \n",
    "#         atom_size: int, \n",
    "#         support: torch.Tensor\n",
    "#     ):\n",
    "#         \"\"\"Initialization.\"\"\"\n",
    "#         super(Network, self).__init__()\n",
    "        \n",
    "#         self.support = support\n",
    "#         self.out_dim = out_dim\n",
    "#         self.atom_size = atom_size\n",
    "\n",
    "#         # set common feature layer\n",
    "#         self.feature_layer = nn.Sequential(\n",
    "#             nn.Linear(in_dim, 128), \n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "#         # set advantage layer\n",
    "#         self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "#         self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "#         # set value layer\n",
    "#         self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "#         self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         \"\"\"Forward method implementation.\"\"\"\n",
    "#         dist = self.dist(x)\n",
    "#         q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "#         return q\n",
    "    \n",
    "#     def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         \"\"\"Get distribution for atoms.\"\"\"\n",
    "#         feature = self.feature_layer(x)\n",
    "#         adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "#         val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "#         advantage = self.advantage_layer(adv_hid).view(\n",
    "#             -1, self.out_dim, self.atom_size\n",
    "#         )\n",
    "#         value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "#         q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "#         dist = F.softmax(q_atoms, dim=-1)\n",
    "#         dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "#         return dist\n",
    "    \n",
    "#     def reset_noise(self):\n",
    "#         \"\"\"Reset all noisy layers.\"\"\"\n",
    "#         self.advantage_hidden_layer.reset_noise()\n",
    "#         self.advantage_layer.reset_noise()\n",
    "#         self.value_hidden_layer.reset_noise()\n",
    "#         self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        # self.feature_layer = nn.Sequential(\n",
    "        #     nn.Linear(in_dim, 128), \n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "        \n",
    "        # set common feature layer\n",
    "\n",
    "        # ORG\n",
    "        # self.feature_layer = nn.Sequential(\n",
    "        # nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Flatten(),\n",
    "        # nn.Linear(3136, 128), # Output shape is [64, out_dim] \n",
    "        # nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "        # Accroding to paper\n",
    "        self.feature_layer = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=512, kernel_size=4, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels=64, kernel_size=3, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(3136, 128), # Output shape is [64, out_dim] \n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128, std_init=0.5)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size, std_init=0.5)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128, std_init=0.5)\n",
    "        self.value_layer = NoisyLinear(128, atom_size, std_init=0.5)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2) # [64, 7]\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "\n",
    "        # [64, 7, 51]\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "        lr: float = 0.001,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        #obs_dim = env.observation_space.shape[0]\n",
    "        print(f\"Learning rate: {lr}\")\n",
    "        obs_dim = env.observation_space.shape\n",
    "        \n",
    "        \n",
    "        action_dim = env.action_space.n\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(), lr=lr, eps=15e-5)\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "\n",
    "        # Convert input\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        selected_action = self.dqn(state.to(self.device)).argmax()    \n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        \n",
    "        return selected_action\n",
    "\n",
    "    # def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "    #     \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "    #     print(action)\n",
    "    #     next_state, reward, done, _ = self.env.step(int(action))\n",
    "\n",
    "    #     if not self.is_test:\n",
    "    #         self.transition += [reward, next_state, done]\n",
    "            \n",
    "    #         # N-step transition\n",
    "    #         if self.use_n_step:\n",
    "    #             one_step_transition = self.memory_n.store(*self.transition)\n",
    "    #         # 1-step transition\n",
    "    #         else:\n",
    "    #             one_step_transition = self.transition\n",
    "\n",
    "    #         # add a single step transition\n",
    "    #         if one_step_transition:\n",
    "    #             self.memory.store(*one_step_transition)\n",
    "    \n",
    "    #     return next_state, reward, done\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        # print(action)\n",
    "        done = False\n",
    "\n",
    "        \n",
    "        #for _ in range(randint(1,2)): This is old one\n",
    "        for _ in range(4): # Do the same action for 4 consecutive frames.\n",
    "            next_state, reward, done, _ = self.env.step(int(action))\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "\n",
    "        return next_state, reward, done\n",
    "    \n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        #clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "\n",
    "        # Modification to convert lazyframe object to numpy array.\n",
    "        state = np.array(state)\n",
    "\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "        #counter = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "\n",
    "\n",
    "            \n",
    "            # Modification to convert lazyframe object to numpy array.\n",
    "            state = np.array(state)\n",
    "            action = self.select_action(state)\n",
    "            \n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "\n",
    "            # Terminate state if mario get struck\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                writer.add_scalar(\"Loss/Train\", loss, frame_idx)\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # Writing\n",
    "            writer.add_scalar(\"Score/Train\", score, frame_idx)\n",
    "\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "\n",
    "            # Save models & loss\n",
    "            if (frame_idx  % 100000) == 0:\n",
    "                # loss_file = open(f'./loss/loss_{frame_idx}.pkl', \"wb\")\n",
    "                # pickle.dump(losses, loss_file)\n",
    "                # score_file = open(f'./score/score_{frame_idx}.pkl', \"wb\")\n",
    "                # pickle.dump(scores, score_file)\n",
    "                path = f\"./models/rainbow_at_{frame_idx}.pth\"\n",
    "                torch.save(self.dqn.state_dict(), path)\n",
    "                \n",
    "        self.env.close()\n",
    "\n",
    "    def train_live(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        \n",
    "        state = self.env.reset()\n",
    "\n",
    "        # Modification to convert lazyframe object to numpy array.\n",
    "        state = np.array(state)\n",
    "\n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            \n",
    "            # Modification to convert lazyframe object to numpy array.\n",
    "            state = np.array(state)\n",
    "            action = self.select_action(state)\n",
    "            \n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "\n",
    "            # Render\n",
    "            self.env.render()\n",
    "\n",
    "            # Save models & loss\n",
    "            if (frame_idx  % 100000 + 1) == 0:\n",
    "                # loss_file = open(f'./loss/loss_{frame_idx}', \"wb\")\n",
    "                # pickle.dump(losses, loss_file)\n",
    "                # score_file = open(f'./score/score_{frame_idx}', \"wb\")\n",
    "                # pickle.dump(scores, score_file)\n",
    "                path = f\"./models/rainbow_at_{frame_idx}.pth\"\n",
    "                torch.save(self.dqn.state_dict(), path)\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        # for recording a video\n",
    "        naive_env = self.env\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n",
    "        \n",
    "        state = self.env.reset()\n",
    "        state = np.array(state)\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            state = np.array(state)\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "        \n",
    "        # reset\n",
    "        self.env = naive_env\n",
    "\n",
    "    def test_live(self):\n",
    "        self.is_test = True\n",
    "\n",
    "        state = self.env.reset()\n",
    "        # Convert state\n",
    "        state = np.array(state)\n",
    "        done = False\n",
    "        score = 0\n",
    "        counter = 0\n",
    "        #while not done:\n",
    "        while True:\n",
    "            \n",
    "            if done:\n",
    "                state = self.env.reset()\n",
    "                state = np.array(state)\n",
    "            \n",
    "\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            # Convert state\n",
    "            state = np.array(state)\n",
    "\n",
    "            score += reward\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            self.env.render()\n",
    "        \n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : 2\n"
     ]
    }
   ],
   "source": [
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v3\")\n",
    "force_right = [\"right\"], [\"right\", \"A\"]\n",
    "env = JoypadSpace(env, force_right)\n",
    "\n",
    "env = FrameStack(ResizeObservation(GrayScaleObservation(SkipFrame(env, skip=4)), shape=84), num_stack=4)\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "print(\"Action :\",n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[777]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)\n",
    "env.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 6.25e-05\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 200000\n",
    "memory_size = 300000\n",
    "batch_size = 32\n",
    "target_update = 4\n",
    "\n",
    "# train\n",
    "# already tried (6.25e-5, 6.25e-7, 6.25e-10)\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, n_step=3, lr=6.25e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save all buffer\n",
    "# import pickle\n",
    "\n",
    "# file = open(\"./experience/obs/obs_buf.pkl\", \"wb\")\n",
    "# pickle.dump(agent.memory.obs_buf, file)\n",
    "\n",
    "# file = open(\"./experience/next_obs/next_obs_buf.pkl\", \"wb\")\n",
    "# pickle.dump(agent.memory.next_obs_buf, file)\n",
    "\n",
    "# file = open(\"./experience/acts/acts_buf.pkl\", \"wb\")\n",
    "# pickle.dump(agent.memory.acts_buf, file)\n",
    "\n",
    "# file = open(\"./experience/rews/rews_buf.pkl\", \"wb\")\n",
    "# pickle.dump(agent.memory.rews_buf, file)\n",
    "\n",
    "# file = open(\"./experience/done/done_buf.pkl\", \"wb\")\n",
    "# pickle.dump(agent.memory.done_buf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train_live(num_frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load buffer\n",
    "import pickle\n",
    "file = open(\"./experience/obs/obs_buf.pkl\", \"rb\")\n",
    "agent.memory.obs_buf = pickle.load(file)\n",
    "\n",
    "file = open(\"./experience/next_obs/next_obs_buf.pkl\", \"rb\")\n",
    "agent.memory.next_obs_buf = pickle.load(file)\n",
    "\n",
    "file = open(\"./experience/acts/acts_buf.pkl\", \"rb\")\n",
    "\n",
    "\n",
    "file = open(\"./experience/rews/rews_buf.pkl\", \"rb\")\n",
    "\n",
    "file = open(\"./experience/done/done_buf.pkl\", \"rb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tonso\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4504\\3290152694.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdqn_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_live\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4504\\1968606781.py\u001b[0m in \u001b[0;36mtest_live\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4504\\1968606781.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m#for _ in range(randint(1,2)): This is old one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Do the same action for 4 consecutive frames.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\wrappers\\frame_stack.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4504\\3588232437.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# Accumulate reward and repeat the same action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# take the step and record the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_action_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;31m# pass the action to the emulator as an unsigned byte\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[1;31m# get the reward for this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "path = r\"C:\\Users\\Tonso\\DRL\\Rainbow_mario\\models\\rainbow_at_190000.pth\"\n",
    "agent.dqn.load_state_dict(torch.load(path))\n",
    "agent.dqn_target.load_state_dict(torch.load(path))\n",
    "agent.test_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NES Emulator for OpenAI Gym\n",
    "# from nes_py.wrappers import JoypadSpace\n",
    "# # Super Mario environment for OpenAI Gym\n",
    "# import gym_super_mario_bros\n",
    "# from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT \n",
    "\n",
    "# env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
    "# env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# env = FrameStack(ResizeObservation(GrayScaleObservation(SkipFrame(env, skip=4)), shape=84), num_stack=4)\n",
    "\n",
    "# # parameters\n",
    "# num_frames = 500000\n",
    "# memory_size = 300000\n",
    "# batch_size = 32\n",
    "# target_update = 4\n",
    "\n",
    "# # test\n",
    "# agent = DQNAgent(env, memory_size, batch_size, target_update, n_step=3, lr=625e-10)\n",
    "# path = r\"C:\\Users\\Tonso\\DRL\\Rainbow_mario\\models\\rainbow_at_300000.pth\"\n",
    "# agent.dqn.load_state_dict(torch.load(path))\n",
    "\n",
    "# agent.test_live()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./models/rainbow_200000_frames.pth\"\n",
    "# torch.save(agent.dqn.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Tonso\\DRL\\Rainbow_mario\\models\\rainbow_at_300000.pth\"\n",
    "agent.dqn.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tonso\\AppData\\Roaming\\Python\\Python39\\site-packages\\gym\\wrappers\\record_video.py:41: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\Tonso\\DRL\\Rainbow_mario\\videos\\rainbow folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  146.0\n"
     ]
    }
   ],
   "source": [
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "video_folder=\"videos/rainbow\"\n",
    "agent.test(video_folder=video_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
